variables:
  # Not normally needed, but may be if some script uses `apt-get install`.
  DEBIAN_FRONTEND: noninteractive
  # Locale settings do not affect the build, but might affect tests.
  LC_ALL: C

  CI_REGISTRY_IMAGE: registry.gitlab.isc.org/isc-projects/images/bind9
  CCACHE_DIR: "/ccache"
  SOFTHSM2_CONF: "/var/tmp/softhsm2/softhsm2.conf"

  # VirtualBox driver needs to set build_dir to "/builds" in gitlab-runner.toml
  KYUA_RESULT: "$CI_PROJECT_DIR/kyua.results"

  GIT_DEPTH: 1
  GIT_CLEAN_FLAGS: -ffdxq

  # The following values may be overwritten in GitLab's CI/CD Variables Settings.
  BUILD_PARALLEL_JOBS: 6
  TEST_PARALLEL_JOBS: 4

  CONFIGURE: ./configure
  CLANG_VERSION: 20
  CLANG: "clang-${CLANG_VERSION}"
  SCAN_BUILD: "scan-build-${CLANG_VERSION}"
  LLVM_SYMBOLIZER: "/usr/lib/llvm-${CLANG_VERSION}/bin/llvm-symbolizer"
  ASAN_SYMBOLIZER_PATH: "/usr/lib/llvm-${CLANG_VERSION}/bin/llvm-symbolizer"

  CFLAGS_COMMON: -fno-omit-frame-pointer -fno-optimize-sibling-calls -O1 -g -Wall -Wextra

  # Pass run-time flags to AddressSanitizer to get core dumps on error.
  ASAN_OPTIONS: abort_on_error=1:disable_coredump=0:unmap_shadow_on_exit=1

  UBSAN_OPTIONS: "halt_on_error=1:abort_on_error=1:disable_coredump=0"

  INSTALL_PATH: "${CI_PROJECT_DIR}/.local"

  # Disable pytest's "cacheprovider" plugin to prevent it from creating
  # cross-testrun files as there is no need to use that feature in CI.
  PYTEST_ADDOPTS: "-p no:cacheprovider"

default:
  # Allow all running CI jobs to be automatically canceled when a new
  # version of a branch is pushed.
  #
  # See: https://docs.gitlab.com/ee/ci/pipelines/settings.html#auto-cancel-redundant-pipelines
  interruptible: true

  # AWS can interrupt the spot instance anytime, so let's retry the job when
  # the interruption event happens to avoid a pipeline failure.
  retry:
    max: 2
    when:
      - runner_system_failure

stages:
  - precheck
  - build
  - unit
  - system
  - performance
  - docs
  - postcheck
  - postmerge
  - release

### Runner Tag Templates

# Autoscaling GitLab Runner on AWS EC2 (amd64)

.linux-amd64: &linux_amd64
  tags:
    - linux
    - aws
    - runner-manager
    - amd64

# Autoscaling GitLab Runner on AWS EC2 (arm64)

.linux-arm64: &linux_arm64
  tags:
    - linux
    - aws
    - runner-manager
    - aarch64

### Docker Image Templates

# Alpine Linux

.alpine-3.20-amd64: &alpine_3_20_amd64_image
  image: "$CI_REGISTRY_IMAGE:alpine-3.20-amd64"
  <<: *linux_amd64

# Oracle Linux

.oraclelinux-8-amd64: &oraclelinux_8_amd64_image
  image: "$CI_REGISTRY_IMAGE:oraclelinux-8-amd64"
  <<: *linux_amd64

.oraclelinux-9-amd64: &oraclelinux_9_amd64_image
  image: "$CI_REGISTRY_IMAGE:oraclelinux-9-amd64"
  <<: *linux_amd64

# Debian

.debian-bookworm-amd64: &debian_bookworm_amd64_image
  image: "$CI_REGISTRY_IMAGE:debian-bookworm-amd64"
  <<: *linux_amd64

.debian-bookworm-amd64cross32: &debian_bookworm_amd64cross32_image
  image: "$CI_REGISTRY_IMAGE:debian-bookworm-amd64cross32"
  <<: *linux_amd64

.debian-sid-amd64: &debian_sid_amd64_image
  image: "$CI_REGISTRY_IMAGE:debian-sid-amd64"
  <<: *linux_amd64

# openSUSE Tumbleweed

.tumbleweed-latest-amd64: &tumbleweed_latest_amd64_image
  image: "$CI_REGISTRY_IMAGE:tumbleweed-latest-amd64"
  <<: *linux_amd64

# Fedora

.fedora-40-amd64: &fedora_40_amd64_image
  image: "$CI_REGISTRY_IMAGE:fedora-40-amd64"
  <<: *linux_amd64

.fedora-40-arm64: &fedora_40_arm64_image
  image: "$CI_REGISTRY_IMAGE:fedora-40-arm64"
  <<: *linux_arm64

# Ubuntu

.ubuntu-focal-amd64: &ubuntu_focal_amd64_image
  image: "$CI_REGISTRY_IMAGE:ubuntu-focal-amd64"
  <<: *linux_amd64

.ubuntu-jammy-amd64: &ubuntu_jammy_amd64_image
  image: "$CI_REGISTRY_IMAGE:ubuntu-jammy-amd64"
  <<: *linux_amd64

.ubuntu-noble-amd64: &ubuntu_noble_amd64_image
  image: "$CI_REGISTRY_IMAGE:ubuntu-noble-amd64"
  <<: *linux_amd64

# Base image
# This is a meta image that is used as a base for non-specific jobs

.base: &base_image
  <<: *debian_bookworm_amd64_image

### Job Templates

.api-pipelines-schedules-tags-triggers-web-triggering-rules: &api_pipelines_schedules_tags_triggers_web_triggering_rules
  only:
    - api
    - pipelines
    - schedules
    - tags
    - triggers
    - web

.api-pipelines-schedules-triggers-web-triggering-rules: &api_pipelines_schedules_triggers_web_triggering_rules
  only:
    - api
    - pipelines
    - schedules
    - triggers
    - web

.default-triggering-rules: &default_triggering_rules
  only:
    - api
    - merge_requests
    - pipelines
    - schedules
    - tags
    - triggers
    - web

.precheck: &precheck_job
  <<: *default_triggering_rules
  <<: *base_image
  stage: precheck

.configure: &configure
    - ${CONFIGURE}
      --disable-maintainer-mode
      --enable-developer
      --with-libtool
      --disable-static
      --enable-option-checking=fatal
      --enable-dnstap
      --with-cmocka
      --with-libxml2
      --with-json-c
      --without-make-clean
      $EXTRA_CONFIGURE
      || (test -s config.log && cat config.log; exit 1)

.build: &build_job
  <<: *default_triggering_rules
  stage: build
  before_script:
    - test -w "${CCACHE_DIR}" && export PATH="/usr/lib/ccache:${PATH}"
    - test -n "${OOT_BUILD_WORKSPACE}" && mkdir "${OOT_BUILD_WORKSPACE}" && cd "${OOT_BUILD_WORKSPACE}"
  script:
    - *configure
    - test -n "${SKIP_MAKE_DEPEND}" || make -j${BUILD_PARALLEL_JOBS:-1} depend 2>&1 | tee make-depend.log
    - test -n "${SKIP_MAKE_DEPEND}" || ( ! grep -F "error:" make-depend.log )
    - make -j${BUILD_PARALLEL_JOBS:-1} -k all V=1
    - test -z "${RUN_MAKE_INSTALL}" || make DESTDIR="${INSTALL_PATH}" install
    - test -z "${RUN_MAKE_INSTALL}" || DESTDIR="${INSTALL_PATH}" sh util/check-make-install
    - if [[ "${CFLAGS}" == *"-fsanitize=address"* ]]; then ( ! grep -F AddressSanitizer config.log ); fi
    - test -z "${CROSS_COMPILATION}" || grep -F -A 1 "checking whether we are cross compiling" config.log | grep -q "result.*yes"
    - test -z "${CROSS_COMPILATION}" || file lib/dns/gen | grep -F -q "ELF 64-bit LSB"
    - test -z "${CROSS_COMPILATION}" || ( ! git ls-files -z --others --exclude lib/dns/gen | xargs -0 file | grep "ELF 64-bit LSB" )
  artifacts:
    untracked: true
    when: always
  needs: []

.setup_interfaces: &setup_interfaces
    - if [ "$(id -u)" -eq "0" ]; then
        sh -x bin/tests/system/ifconfig.sh up;
      else
        sudo sh -x bin/tests/system/ifconfig.sh up;
      fi

.setup_softhsm: &setup_softhsm
    - export SLOT=$(sh -x bin/tests/prepare-softhsm2.sh)
    - test -n "${SLOT}" && test "${SLOT}" -gt 0

.system_test_common: &system_test_common
  <<: *default_triggering_rules
  stage: system
  before_script:
    - *setup_interfaces
    - *setup_softhsm
  script:
    - ( cd bin/tests/system && make -j${TEST_PARALLEL_JOBS:-1} -k test V=1 )
    - test -s bin/tests/system/systests.output
    - if git rev-parse > /dev/null 2>&1; then ( ! grep "^I:.*:file.*not removed$" bin/tests/system/systests.output ); fi
    - '( ! grep -F "grep: warning:" bin/tests/system/systests.output )'

.system_test: &system_test_job
  <<: *system_test_common
  artifacts:
    untracked: true
    when: on_failure

.system_test_gcov: &system_test_gcov_job
  <<: *system_test_common
  artifacts:
    untracked: true
    when: always

.kyua_report: &kyua_report_html
  - kyua --logfile /dev/null report-html
         --force
         --results-file "$KYUA_RESULT"
         --results-filter ""
         --output kyua_html > /dev/null

.unit_test_common: &unit_test_common
  <<: *default_triggering_rules
  stage: unit
  before_script:
    - *setup_softhsm
  script:
    - make unit
  after_script:
    - *kyua_report_html

.unit_test: &unit_test_job
  <<: *unit_test_common
  artifacts:
    untracked: true
    when: on_failure

.unit_test_gcov: &unit_test_gcov_job
  <<: *unit_test_common
  artifacts:
    untracked: true
    when: always

.respdiff: &respdiff_job
  stage: system
  before_script:
    - *configure
    - make -j${BUILD_PARALLEL_JOBS:-1} V=1
    - *setup_interfaces
    - git clone --depth 1 https://gitlab.isc.org/isc-projects/bind9-qa.git
    - cd bind9-qa/respdiff
  needs: []
  artifacts:
    paths:
      - bind9-qa/respdiff
    exclude:
      - bind9-qa/respdiff/rspworkdir/data.mdb # Exclude a 10 GB file.
    untracked: true
    when: always

### Job Definitions

# Jobs in the precheck stage

misc:
  <<: *precheck_job
  script:
    - sh util/check-ans-prereq.sh
    - xmllint --noout --nonet `git ls-files '*.xml' '*.docbook'`
    - sh util/check-categories.sh
    - sh util/xmllint-html.sh
  artifacts:
    when: on_failure

changes:
  <<: *precheck_job
  except:
    - pipelines
  script:
    - sh util/tabify-changes < CHANGES > CHANGES.tmp
    - diff -urNap CHANGES CHANGES.tmp
    - perl util/check-changes CHANGES
    - sh util/check-line-length.sh CHANGES
    - rm CHANGES.tmp
  needs: []

black:
  <<: *precheck_job
  script:
    - black $(git ls-files '*.py' '*.py.in')
    - git diff > black.patch
    - if test "$(git status --porcelain | grep -Ev '\?\?' | wc -l)" -gt "0"; then git status --short; exit 1; fi
  artifacts:
    paths:
      - black.patch
    expire_in: "1 week"
    when: on_failure

coccinelle:
  <<: *precheck_job
  script:
    - util/check-cocci
    - if test "$(git status --porcelain | grep -Ev '\?\?' | wc -l)" -gt "0"; then git status --short; exit 1; fi

reuse:
  <<: *precheck_job
  image:
    name: docker.io/fsfe/reuse:latest
    entrypoint: [""]
  script:
    - reuse lint

shfmt:
  <<: *precheck_job
  needs: []
  script:
    - shfmt -w -i 2 -ci -bn bin/tests/system/ util/ $(find bin/tests/system/ -name "*.sh.in")
    - git diff > shfmt.patch
    - if test "$(git status --porcelain | grep -Ev '\?\?' | wc -l)" -gt "0"; then git status --short; exit 1; fi
  artifacts:
    paths:
      - shfmt.patch
    expire_in: "1 week"
    when: on_failure

danger:
  <<: *precheck_job
  script:
    - pip install git+https://gitlab.isc.org/isc-projects/hazard.git
    - hazard
  only:
    refs:
      - merge_requests

pylint:
  <<: *default_triggering_rules
  <<: *base_image
  stage: postcheck
  script:
    - *configure
    - export PYTHONPATH="$PYTHONPATH:$CI_PROJECT_DIR/bin/python"
    - pylint --rcfile $CI_PROJECT_DIR/.pylintrc $(git ls-files '*.py' | grep -vE '(ans\.py|dangerfile\.py|^bin/tests/system/)')
      # Ignore Pylint wrong-import-position error in system test to enable use of pytest.importorskip
    - pylint --rcfile $CI_PROJECT_DIR/.pylintrc --disable=wrong-import-position $(git ls-files 'bin/tests/system/*.py' | grep -vE 'ans\.py')
  needs: []

checkbashisms:
  <<: *precheck_job
  script:
    - checkbashisms $(find . -path './.git' -prune -o -type f -exec sh -c 'head -n 1 "{}" | grep -qsF "#!/bin/sh"' \; -print | sed -e '/^\.\/install-sh$/d')

tarball-create:
  stage: precheck
  <<: *base_image
  <<: *default_triggering_rules
  script:
    - source version
    - export BIND9_VERSION="${MAJORVER}.${MINORVER}${PATCHVER:+.}${PATCHVER}${RELEASETYPE}${RELEASEVER}${EXTENSIONS}"
    - export BIND_DIRECTORY="bind-${BIND9_VERSION}"
    - git archive --prefix="${BIND_DIRECTORY}/" --output="${BIND_DIRECTORY}.tar" HEAD
    - mkdir "${BIND_DIRECTORY}"
    - echo "SRCID=$(git rev-list --max-count=1 HEAD | cut -b1-7)" > "${BIND_DIRECTORY}/srcid"
    - tar --append --file="${BIND_DIRECTORY}.tar" "${BIND_DIRECTORY}/srcid"
    - sphinx-build -b man -d "${BIND_DIRECTORY}/tmp/.doctrees/" -W -a -v -c doc/man/ -D version="@BIND9_VERSION@" -D today="@RELEASE_DATE@" -D release="@BIND9_VERSIONSTRING@" doc/man "${BIND_DIRECTORY}/doc/man"
    - rm -rf "${BIND_DIRECTORY}/tmp/.doctrees/"
    - for man in "${BIND_DIRECTORY}/doc/man/"*; do mv "$man" "$man"in; done
    - tar --append --file="${BIND_DIRECTORY}.tar" "${BIND_DIRECTORY}/doc/man/"*in
    - xz "${BIND_DIRECTORY}.tar"
  artifacts:
    paths:
      - bind-*.tar.xz

# Jobs for doc builds on Debian 12 "bookworm" (amd64)

docs:
  <<: *default_triggering_rules
  <<: *base_image
  stage: docs
  before_script:
    - test -w "${CCACHE_DIR}" && export PATH="/usr/lib/ccache:${PATH}"
    - test -n "${OOT_BUILD_WORKSPACE}" && mkdir "${OOT_BUILD_WORKSPACE}" && cd "${OOT_BUILD_WORKSPACE}"
  script:
    - *configure
    - make maintainer-clean
    - autoreconf2.69 -fi
    - *configure
    - make -j${BUILD_PARALLEL_JOBS:-1} all V=1
    - make -j${BUILD_PARALLEL_JOBS:-1} doc V=1
    - if test "$(git status --porcelain | grep -Ev '\?\?' | grep -v -F -e aclocal.m4 -e configure -e ltmain.sh -e bin/named/bind9.xsl.h -e m4/ | wc -l)" -gt "0"; then git status --short; exit 1; fi
    - find doc/man/ -maxdepth 1 -name "*.[0-9]" -exec mandoc -T lint "{}" \; | ( ! grep -v -e "skipping paragraph macro. sp after" -e "unknown font, skipping request. ft C" -e "input text line longer than 80 bytes" )
  artifacts:
    paths:
      - doc/arm/
      - doc/man/
      - doc/misc/
    when: always
  needs: []

docs:pdf:
  <<: *api_pipelines_schedules_tags_triggers_web_triggering_rules
  <<: *base_image
  stage: docs
  before_script:
    - apt-get update
    - apt-get -y install qpdf texlive-full texlive-xetex xindy
  script:
    - *configure
    - make -C doc/arm/ pdf V=1
    - qpdf --check doc/arm/_build/latex/Bv9ARM.pdf
  artifacts:
    untracked: true
  needs: []

# Job detecting named.conf breakage introduced since the previous point release

cross-version-config-tests:
  stage: system
  <<: *base_image
  <<: *default_triggering_rules
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    # Disable option checking to prevent problems with new default options in
    # the &configure anchor.
    EXTRA_CONFIGURE: "--disable-option-checking"
  script:
    # Exclude the dyndb test from the system test as the sample library can't
    # locate the libdns library from the BIND 9 baseline version.
    - sed -i '/^dyndb \\$/d' bin/tests/system/conf.sh.common
    - *configure
    - *setup_interfaces
    - make -j${BUILD_PARALLEL_JOBS:-1}
    - export BIND_BRANCH=16
    # When testing a .0 release, compare it against the previous development
    # release (e.g., 9.19.0 and 9.18.0 should both be compared against 9.17.22).
    - if [ "$(sed -n -E "s|^m4_define\(\[bind_VERSION_PATCH\], ([0-9]+)\)dnl$|\1|p" configure.ac)" = "0" ]; then export BIND_BRANCH=$((BIND_BRANCH - 1 - (BIND_BRANCH % 2))); fi
    - BASELINE="$(curl -s "https://gitlab.isc.org/api/v4/projects/1/repository/tags?search=^v9.${BIND_BRANCH}&order_by=version" | jq -r ".[0].name")"
    - git clone --branch "${BASELINE}" --depth 1 https://gitlab.isc.org/isc-projects/bind9.git "bind-${BASELINE}"
    - cd "bind-${BASELINE}"
    - *configure
    - make -j${BUILD_PARALLEL_JOBS:-1}
    # The cross-version-config-tests job would fail when a system test is
    # removed from the upcoming release. To avoid this, remove the system test
    # also from the $BIND_BASELINE_VERSION.
    - find bin/tests/system/ -mindepth 1 -maxdepth 1 -type d -exec sh -c 'test -e ../"$0" || rm -rfv -- "$0"' {} \;
    - cd bin/tests/system
    # Neutralize shell and pytests; in effect, "nsX" servers are just started
    # and stopped, thus configuration checked.
    - truncate --size=0 */tests{.sh,*.py}
    # Run the setup phase of all system tests in the most recently tagged BIND 9
    # release using the binaries built for the current BIND 9 version.  This
    # intends to detect obvious backward compatibility issues with the latter.
    - sed -i -E "s|(export TOP)=.*|\1=${CI_PROJECT_DIR}|" conf.sh
    - make -j${TEST_PARALLEL_JOBS:-1} -k check V=1
  artifacts:
    paths:
      - bind-*
    untracked: true
    expire_in: "1 day"
    when: on_failure
  needs: []

# Jobs for regular GCC builds on Alpine Linux 3.20 (amd64)

gcc:alpine3.20:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--without-gssapi"
  <<: *alpine_3_20_amd64_image
  <<: *build_job

system:gcc:alpine3.20:amd64:
  <<: *alpine_3_20_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:alpine3.20:amd64
      artifacts: true

unit:gcc:alpine3.20:amd64:
  <<: *alpine_3_20_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:alpine3.20:amd64
      artifacts: true

# Jobs for regular GCC builds on Oracle Linux 8 (amd64)

gcc:oraclelinux8:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--enable-buffer-useinline --with-libidn2"
  <<: *oraclelinux_8_amd64_image
  <<: *build_job

system:gcc:oraclelinux8:amd64:
  <<: *oraclelinux_8_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:oraclelinux8:amd64
      artifacts: true

unit:gcc:oraclelinux8:amd64:
  <<: *oraclelinux_8_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:oraclelinux8:amd64
      artifacts: true

# Jobs for regular GCC builds on Oracle Linux 9 (amd64)

gcc:oraclelinux9:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--with-libidn2"
  <<: *oraclelinux_9_amd64_image
  <<: *build_job

system:gcc:oraclelinux9:amd64:
  <<: *oraclelinux_9_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:oraclelinux9:amd64
      artifacts: true

unit:gcc:oraclelinux9:amd64:
  <<: *oraclelinux_9_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:oraclelinux9:amd64
      artifacts: true

gcc:tarball:nosphinx:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--with-libidn2 --disable-developer"
    RUN_MAKE_INSTALL: 1
  <<: *oraclelinux_9_amd64_image
  <<: *build_job
  before_script:
    - (! command -v sphinx-build >/dev/null)
    - tar --extract --file bind-*.tar.xz
    - rm -f bind-*.tar.xz
    - cd bind-*
  needs:
    - job: tarball-create
      artifacts: true

# Jobs for regular GCC builds on Ubuntu 24.04 Noble Numbat (amd64)

gcc:noble:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--with-libidn2"
  <<: *ubuntu_noble_amd64_image
  <<: *build_job

system:gcc:noble:amd64:
  <<: *ubuntu_noble_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:noble:amd64
      artifacts: true

unit:gcc:noble:amd64:
  <<: *ubuntu_noble_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:noble:amd64
      artifacts: true

# Jobs for regular GCC builds on Debian 12 "bookworm" (amd64)

gcc:bookworm:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} --coverage -O0"
    EXTRA_CONFIGURE: "--with-libidn2"
    LDFLAGS: "--coverage"
  <<: *debian_bookworm_amd64_image
  <<: *build_job

system:gcc:bookworm:amd64:
  <<: *debian_bookworm_amd64_image
  <<: *system_test_gcov_job
  variables:
    CI_ENABLE_ALL_TESTS: 1
  needs:
    - job: unit:gcc:bookworm:amd64
      artifacts: true

unit:gcc:bookworm:amd64:
  <<: *debian_bookworm_amd64_image
  <<: *unit_test_gcov_job
  variables:
    CI_ENABLE_ALL_TESTS: 1
  needs:
    - job: gcc:bookworm:amd64
      artifacts: true

# Build job for cross-compiled GCC builds on 64-bit Debian 12 "bookworm"
# (amd64) with 32-bit BIND 9.

gcc:bookworm:amd64cross32:
  variables:
    BUILD_CC: gcc
    BUILD_CFLAGS: "${CFLAGS_COMMON}"
    CFLAGS: "${CFLAGS_COMMON}"
    CROSS_COMPILATION: 1
    EXTRA_CONFIGURE: "--build=x86_64-linux-gnu --host=i686-linux-gnu --with-libidn2"
  <<: *debian_bookworm_amd64cross32_image
  <<: *build_job

# Jobs for scan-build builds on Debian 12 "bookworm" (amd64)

.scan_build: &scan_build
  - ${SCAN_BUILD} --html-title="BIND 9 ($CI_COMMIT_SHORT_SHA)"
                  --keep-cc
                  --status-bugs
                  --keep-going
                  -o scan-build.reports make -j${BUILD_PARALLEL_JOBS:-1} all V=1

scan-build:
  <<: *default_triggering_rules
  <<: *base_image
  stage: postcheck
  variables:
    CC: "${CLANG}"
    CFLAGS: "${CFLAGS_COMMON}"
    CONFIGURE: "${SCAN_BUILD} ./configure"
    EXTRA_CONFIGURE: "--with-libidn2"
  script:
    - *configure
    - *scan_build
  artifacts:
    paths:
      - scan-build.reports/
    when: on_failure
  needs: []

# Jobs for regular GCC builds on Debian "sid" (amd64)
# Also tests configration option: --without-lmdb.

gcc:sid:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -O3"
    EXTRA_CONFIGURE: "--with-libidn2 --without-lmdb --without-python"
    RUN_MAKE_INSTALL: 1
  <<: *debian_sid_amd64_image
  <<: *build_job

system:gcc:sid:amd64:
  <<: *debian_sid_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:sid:amd64
      artifacts: true

unit:gcc:sid:amd64:
  <<: *debian_sid_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:sid:amd64
      artifacts: true

# Job for out-of-tree GCC build on Debian 12 "bookworm" (amd64)
# Also tests configration option: --with-lmdb.

gcc:out-of-tree:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og"
    CONFIGURE: ../configure
    EXTRA_CONFIGURE: "--with-libidn2 --with-lmdb"
    SKIP_MAKE_DEPEND: 1
    RUN_MAKE_INSTALL: 1
    OOT_BUILD_WORKSPACE: workspace
  <<: *base_image
  <<: *build_job

# Jobs for tarball GCC builds on Debian 12 "bookworm" (amd64)

gcc:tarball:
  variables:
    CC: gcc
    EXTRA_CONFIGURE: "--with-libidn2"
    RUN_MAKE_INSTALL: 1
  <<: *base_image
  <<: *build_job
  before_script:
    - tar --extract --file bind-*.tar.xz
    - rm -f bind-*.tar.xz
    - cd bind-*
  needs:
    - job: tarball-create
      artifacts: true

system:gcc:tarball:
  <<: *base_image
  <<: *system_test_job
  <<: *api_pipelines_schedules_tags_triggers_web_triggering_rules
  before_script:
    - cd bind-*
    - *setup_interfaces
  needs:
    - job: gcc:tarball
      artifacts: true

unit:gcc:tarball:
  <<: *base_image
  <<: *unit_test_job
  <<: *api_pipelines_schedules_tags_triggers_web_triggering_rules
  before_script:
    - cd bind-*
  needs:
    - job: gcc:tarball
      artifacts: true

# Jobs for debug GCC builds on openSUSE Tumbleweed (amd64)

gcc:tumbleweed:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -DDEBUG"
    EXTRA_CONFIGURE: "--with-libidn2 --with-gssapi=krb5-config"
  <<: *tumbleweed_latest_amd64_image
  <<: *build_job

system:gcc:tumbleweed:amd64:
  <<: *tumbleweed_latest_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:tumbleweed:amd64
      artifacts: true

# Jobs for regular GCC builds on Ubuntu 20.04 Focal Fossa (amd64)

gcc:focal:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og"
    EXTRA_CONFIGURE: "--with-libidn2 --with-gssapi=/usr --disable-geoip --without-cmocka"
  <<: *ubuntu_focal_amd64_image
  <<: *build_job

system:gcc:focal:amd64:
  <<: *ubuntu_focal_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:focal:amd64
      artifacts: true

# Jobs for regular GCC builds on Ubuntu 22.04 Jammy Jellyfish (amd64)

gcc:jammy:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -O2"
    EXTRA_CONFIGURE: "--with-libidn2 --disable-dnstap --with-gssapi"
  <<: *ubuntu_jammy_amd64_image
  <<: *build_job

system:gcc:jammy:amd64:
  <<: *ubuntu_jammy_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:jammy:amd64
      artifacts: true

unit:gcc:jammy:amd64:
  <<: *ubuntu_jammy_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:jammy:amd64
      artifacts: true

# Jobs for ASAN builds on Fedora 40 (amd64)

gcc:asan:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -fsanitize=address,undefined -DISC_MEM_USE_INTERNAL_MALLOC=0"
    LDFLAGS: "-fsanitize=address,undefined"
    EXTRA_CONFIGURE: "--with-libidn2"
  <<: *fedora_40_amd64_image
  <<: *build_job

system:gcc:asan:
  <<: *fedora_40_amd64_image
  <<: *system_test_job
  needs:
    - job: gcc:asan
      artifacts: true

unit:gcc:asan:
  <<: *fedora_40_amd64_image
  <<: *unit_test_job
  needs:
    - job: gcc:asan
      artifacts: true

clang:asan:
  variables:
    CC: ${CLANG}
    CFLAGS: "${CFLAGS_COMMON} -fsanitize=address,undefined -DISC_MEM_USE_INTERNAL_MALLOC=0"
    LDFLAGS: "-fsanitize=address,undefined"
    EXTRA_CONFIGURE: "--with-libidn2"
  <<: *base_image
  <<: *build_job

system:clang:asan:
  <<: *base_image
  <<: *system_test_job
  needs:
    - job: clang:asan
      artifacts: true

unit:clang:asan:
  <<: *base_image
  <<: *unit_test_job
  needs:
    - job: clang:asan
      artifacts: true

# Jobs for Clang builds on Debian 12 "bookworm" (amd64)

clang:bookworm:amd64:
  variables:
    CC: ${CLANG}
    CFLAGS: "${CFLAGS_COMMON} -Wenum-conversion"
    EXTRA_CONFIGURE: "--with-python=python3"
  <<: *debian_bookworm_amd64_image
  <<: *build_job

system:clang:bookworm:amd64:
  <<: *debian_bookworm_amd64_image
  <<: *system_test_job
  needs:
    - job: clang:bookworm:amd64
      artifacts: true

unit:clang:bookworm:amd64:
  <<: *debian_bookworm_amd64_image
  <<: *unit_test_job
  needs:
    - job: clang:bookworm:amd64
      artifacts: true

# Jobs with libtool disabled

nolibtool:sid:amd64:
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON}"
    EXTRA_CONFIGURE: "--with-libidn2 --without-libtool --with-dlopen --without-python"
  <<: *debian_sid_amd64_image
  <<: *build_job

system:nolibtool:sid:amd64:
  <<: *debian_sid_amd64_image
  <<: *system_test_job
  needs:
    - job: nolibtool:sid:amd64
      artifacts: true

unit:nolibtool:sid:amd64:
  <<: *debian_sid_amd64_image
  <<: *unit_test_job
  needs:
    - job: nolibtool:sid:amd64
      artifacts: true

# Job producing a release directory

release:
  <<: *base_image
  stage: release
  script:
    # Determine BIND version
    - source version
    - export BIND_DIRECTORY="bind-${MAJORVER}.${MINORVER}.${PATCHVER}${RELEASETYPE}${RELEASEVER}"
    # Prepare release tarball contents (tarballs + zips + documentation)
    - mkdir -p "${BIND_DIRECTORY}-release/doc/arm"
    - pushd "${BIND_DIRECTORY}-release"
    - mv "../${BIND_DIRECTORY}.tar.xz" .
    - tar --extract --file="${BIND_DIRECTORY}.tar.xz"
    - mv "${BIND_DIRECTORY}"/{CHANGES*,COPYRIGHT,LICENSE,README,srcid} .
    - rm -rf "${BIND_DIRECTORY}"
    - mv "../doc/arm/_build/html" doc/arm/
    - mv "../doc/arm/_build/latex/Bv9ARM.pdf" doc/arm/
    - echo '<!DOCTYPE HTML><html lang="en"><meta http-equiv="refresh" content="0; url=doc/arm/html/notes.html"><title>Redirect</title></html>' > "RELEASE-NOTES-${BIND_DIRECTORY}.html"
    - popd
  needs:
    - job: tarball-create
      artifacts: true
    - job: docs
      artifacts: true
    - job: docs:pdf
      artifacts: true
  only:
    - tags
  artifacts:
    paths:
      - "*-release"
    expire_in: "1 month"

# Job signing the source tarballs in the release directory

sign:
  stage: release
  tags:
    - signer
  script:
    - export RELEASE_DIRECTORY="$(echo *-release)"
    - pushd "${RELEASE_DIRECTORY}"
    - |
      echo
      cat > /tmp/sign-bind9.sh <<EOF
      #!/bin/sh
      {
          for FILE in \$(find "${PWD}" -name "*.tar.xz" | sort); do
              echo ">>> Signing \${FILE}..."
              gpg2 --local-user "\${SIGNING_KEY_FINGERPRINT}" --armor --digest-algo SHA512 --detach-sign --output "\${FILE}.asc" "\${FILE}"
          done
      } 2>&1 | tee "${CI_PROJECT_DIR}/signing.log"
      EOF
      chmod +x /tmp/sign-bind9.sh
      echo -e "\e[31m*** Please sign the releases by following the instructions at:\e[0m"
      echo -e "\e[31m*** \e[0m"
      echo -e "\e[31m*** ${SIGNING_HELP_URL}\e[0m"
      echo -e "\e[31m*** \e[0m"
      echo -e "\e[31m*** Sleeping until files in ${PWD} are signed... ⌛\e[0m"
      while [ "$(find . -name "*.asc" -size +0 | sed "s|\.asc$||" | sort)" != "$(find . -name "*.tar.xz" | sort)" ]; do sleep 10; done
    - popd
    - tar --create --file="${RELEASE_DIRECTORY}.tar.gz" --gzip "${RELEASE_DIRECTORY}"
  artifacts:
    paths:
      - "*.tar.gz"
      - signing.log
    expire_in: never
  needs:
    - job: release
      artifacts: true
  only:
    - tags
  when: manual
  allow_failure: false

# Coverity Scan analysis upload

.coverity_prep: &coverity_prep
  - curl --output /tmp/cov-analysis-linux64.md5 https://scan.coverity.com/download/linux64
         --form project=$COVERITY_SCAN_PROJECT_NAME
         --form token=$COVERITY_SCAN_TOKEN
         --form md5=1
  - curl --output /tmp/cov-analysis-linux64.tgz https://scan.coverity.com/download/linux64
         --form project=$COVERITY_SCAN_PROJECT_NAME
         --form token=$COVERITY_SCAN_TOKEN
  - test "$(md5sum /tmp/cov-analysis-linux64.tgz | awk '{ print $1 }')" = "$(cat /tmp/cov-analysis-linux64.md5)"
  - tar --extract --gzip --file=/tmp/cov-analysis-linux64.tgz --directory=/tmp
  - test -d /tmp/cov-analysis-linux64-*

.coverity_build: &coverity_build
  - /tmp/cov-analysis-linux64-*/bin/cov-build --dir /tmp/cov-int --fs-capture-search . sh -c 'make -j${BUILD_PARALLEL_JOBS:-1} -k all V=1'
  - tar --create --gzip --file=/tmp/cov-int.tar.gz --directory /tmp cov-int
  - curl -v https://scan.coverity.com/builds?project=$COVERITY_SCAN_PROJECT_NAME
        --form token=$COVERITY_SCAN_TOKEN
        --form email=bind-changes@isc.org
        --form file=@/tmp/cov-int.tar.gz
        --form version="$(git rev-parse --short HEAD)"
        --form description="$(git rev-parse --short HEAD) / $CI_COMMIT_TITLE / $CI_COMMIT_REF_NAME:$CI_PIPELINE_ID" 2>&1
        | tee curl-response.txt
  - grep -q 'Build successfully submitted' curl-response.txt

coverity:
  <<: *base_image
  stage: postcheck
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og"
    EXTRA_CONFIGURE: "--with-libidn2"
  script:
    - *coverity_prep
    - *configure
    - *coverity_build
  after_script:
    - mv -v /tmp/cov-int.tar.gz ${CI_PROJECT_DIR}/
  artifacts:
    paths:
      - curl-response.txt
      - cov-int.tar.gz
    expire_in: "1 week"
    when: on_failure
  only:
    variables:
      - $COVERITY_SCAN_PROJECT_NAME
      - $COVERITY_SCAN_TOKEN
  needs: []

# Respdiff tests

respdiff:
  <<: *respdiff_job
  <<: *default_triggering_rules
  <<: *debian_bookworm_amd64_image
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og"
    MAX_DISAGREEMENTS_PERCENTAGE: "0.1"
  script:
    - bash respdiff.sh -s named -q "${PWD}/100k_mixed.txt" -c 3 -w "${PWD}/rspworkdir" "${CI_PROJECT_DIR}" "/usr/local/respdiff-reference-bind/sbin/named"

respdiff:asan:
  <<: *respdiff_job
  <<: *default_triggering_rules
  <<: *debian_bookworm_amd64_image
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og -fsanitize=address,undefined -DISC_MEM_USE_INTERNAL_MALLOC=0"
    LDFLAGS: "-fsanitize=address,undefined"
    MAX_DISAGREEMENTS_PERCENTAGE: "0.1"
  script:
    - bash respdiff.sh -s named -q "${PWD}/100k_mixed.txt" -c 3 -w "${PWD}/rspworkdir" "${CI_PROJECT_DIR}" "/usr/local/respdiff-reference-bind/sbin/named"

respdiff-third-party:
  <<: *respdiff_job
  <<: *default_triggering_rules
  <<: *debian_bookworm_amd64_image
  variables:
    CC: gcc
    CFLAGS: "${CFLAGS_COMMON} -Og"
    MAX_DISAGREEMENTS_PERCENTAGE: "0.2"
  script:
    - bash respdiff.sh -s third_party -q "${PWD}/100k_mixed.txt" -c 1 -w "${PWD}/rspworkdir" "${CI_PROJECT_DIR}"

gcov:
  <<: *base_image
  <<: *default_triggering_rules
  stage: postcheck
  needs:
    - job: system:gcc:bookworm:amd64
      artifacts: true
  script:
    # The "a-conftest.gcno" file is result of the ./configure step and
    # should be removed as it does not belong to the BIND 9 code base.
    - rm a-conftest.gcno
    # Generate XML file in the Cobertura XML format suitable for use by GitLab
    # for the purpose of displaying code coverage information in the diff view
    # of a given merge request.
    - gcovr --exclude-directories bin/tests --exclude-directories doc --exclude-directories fuzz --exclude tests --cobertura-pretty -o coverage.xml
    - gcovr --exclude-directories bin/tests --exclude-directories doc --exclude-directories fuzz --exclude tests --html-details -o coverage.html
    - gcovr --exclude-directories bin/tests --exclude-directories doc --exclude-directories fuzz --exclude tests --txt -o coverage.txt
    - tail -n 3 coverage.txt
  artifacts:
    paths:
      - coverage*.html
      - coverage.css
      - coverage.txt
      - coverage.xml
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

# Pairwise testing of ./configure options

pairwise:
  <<: *base_image
  stage: build
  script:
      - util/pairwise-testing.sh
  artifacts:
    paths:
      - pairwise-commands.txt
      - pairwise-model.txt
      - pairwise-output.*.txt
    when: on_failure
  only:
    variables:
      - $PAIRWISE_TESTING
  needs: []

.post_merge_template: &post_merge
  <<: *base_image
  stage: postmerge
  needs: []
  # post-merge processes should run even if another MR was merged while the job was running (or queued)
  interruptible: false
  variables:
    # automated commits will inherit identification from the user who pressed Merge button
    GIT_COMMITTER_NAME: $GITLAB_USER_NAME
    GIT_COMMITTER_EMAIL: $GITLAB_USER_EMAIL
    # avoid leftover branches from previous jobs
    GIT_STRATEGY: clone
    # assumed max depth of a MR for backport or a rebased force-push
    GIT_DEPTH: 1000
  before_script:
    # force-pushes should not trigger process automation (happens only in -sub branches)
    - >
      echo "previous branch tip: $CI_COMMIT_BEFORE_SHA"
    - set +o pipefail; git log --format='%H' | grep --silent "$CI_COMMIT_BEFORE_SHA" && PREVIOUS_TIP_REACHABLE=1
    - test "$PREVIOUS_TIP_REACHABLE" != "1" && echo "force-push detected, stop" && exit 1
    # non-fast-forward merges are disabled so we have to have merge commit on top
    - MERGE_REQUEST_ID="$(git log -1 --format='%b' | sed --silent -e "s|^See merge request ${CI_PROJECT_PATH}\!||p")"
    - >
      : stop if this is not a merge request in the current project\'s namespace
    - test -n "$MERGE_REQUEST_ID"
    - git clone --depth 1 https://gitlab.isc.org/isc-projects/bind9-qa.git

merged-metadata:
  <<: *post_merge
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && ($CI_COMMIT_REF_NAME =~ /^bind-9.[0-9]+(-sub)?$/ || $CI_COMMIT_REF_NAME =~ /^bind-9.[0-9]+.[0-9]+-release$/ || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH)'
  script:
    - bind9-qa/releng/after_merge.py "$CI_PROJECT_ID" "$MERGE_REQUEST_ID"
